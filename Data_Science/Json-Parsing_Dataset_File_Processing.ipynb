{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0ffda2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageOps, ImageFilter\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import os\n",
    "from math import ceil\n",
    "import os.path\n",
    "#import pycuda.driver as cuda\n",
    "#import pycuda.autoinit\n",
    "#from pycuda.compiler import SourceModule\n",
    "import json\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a6bd3f",
   "metadata": {},
   "source": [
    "# Searching Dataset/file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a479fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "origin_path_prefix = '/home/shkim/Workspace/data/kitti/training/'\n",
    "origin_val_path_prefix = '/home/shkim/Workspace/data/COCO_2017/val2017/'\n",
    "image_prefix = 'image_2/'\n",
    "label_prefix = 'label_2/'\n",
    "coco_origin_path_prefix = '/home/shkim/Workspace/data/COCO_2017/'\n",
    "\n",
    "coco_prefix = 'COCO_2017/'\n",
    "kitti_prefix = 'kitti/'\n",
    "\n",
    "coco_train_image_prefix = 'train2017/'\n",
    "coco_val_image_prefix = 'val2017/'\n",
    "coco_annotation_prefix = 'annotations/'\n",
    "\n",
    "\n",
    "annotation_prefix = 'images_annotated/'\n",
    "\n",
    "tmp_image_name = ''\n",
    "tmp_label_name = ''\n",
    "\n",
    "pngExtension = '.png'\n",
    "txtExtension = '.txt'\n",
    "\n",
    "move_path_prefix = '/home/shkim/Workspace/data/kitti_dataset/'\n",
    "\n",
    "move_coco_prefix = '/home/shkim/Workspace/data/coco_dataset/'\n",
    "\n",
    "view_iter_path = '/home/shkim/Workspace/data/kitti_dataset/image_2'\n",
    "\n",
    "visual_path = move_path_prefix + annotation_prefix + tmp_image_name\n",
    "\n",
    "coco_category_id = [ 'person','bicycle','car','motorcycle','airplane','bus','train','truck','boat','traffic light','fire hydrant','stop sign','parking meter','bench',\n",
    "                    'bird','cat','dog','horse','sheep','cow','elephant','bear','zebra','giraffe','backpack','umbrella','handbag','tie','suitcase','frisbee','skis',\n",
    "                    'snowboard','sports ball','kite','baseball bat','baseball glove','skateboard','surfboard','tennis racket','bottle','wine glass','cup',\n",
    "                    'fork','knife','spoon','bowl','banana','apple','sandwich','orange','broccoli','carrot','hot dog','pizza','donut','cake','chair','couch','potted plant',\n",
    "                    'bed','dining table','toilet','tv','laptop','mouse','remote','keyboard','cell phone','microwave','oven','toaster','sink','refrigerator','book',\n",
    "                    'clock','vase','scissors','teddy bear','hair drier','toothbrush']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6046a1",
   "metadata": {},
   "source": [
    "# Label .txt Parsing & Dataset Label Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795ddd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_label_projection(origin_dataset_image_name, origin_dataset_label_name, dataset_label_name, origin_list):\n",
    "    a = []\n",
    "    b = []\n",
    "    b_tmp = []\n",
    "    f = open(origin_dataset_label_name, 'r')\n",
    "\n",
    "    a = f.read().splitlines()\n",
    "\n",
    "    b= deepcopy(a)\n",
    "\n",
    "\n",
    "    for i in range(len(b)):\n",
    "        b_tmp = b[i].split(' ')\n",
    "        for j in range(4):\n",
    "            if j == 0:\n",
    "                origin_list[0][0] = float(b_tmp[4])\n",
    "                origin_list[0][1] = float(b_tmp[5])\n",
    "                origin_list[0][2] = float(b_tmp[6])\n",
    "                origin_list[0][3] = float(b_tmp[7])\n",
    "                origin_list[1][0] = float(b_tmp[8])\n",
    "                origin_list[1][1] = float(b_tmp[9])\n",
    "                origin_list[1][2] = float(b_tmp[10])\n",
    "                origin_list[2][0] = float(b_tmp[11])\n",
    "                origin_list[2][1] = float(b_tmp[12])\n",
    "                origin_list[2][2] = float(b_tmp[13])\n",
    "            elif j == 1:\n",
    "                #print(origin_list)       \n",
    "                image, new_list = Equirectangular_Projection(origin_dataset_image_name, origin_list)\n",
    "                #print(new_list)\n",
    "            elif j == 2:\n",
    "                if(b_tmp[0] == \"DontCare\"):\n",
    "                    b_tmp[1] = str(donecare_list[0][0])\n",
    "                    b_tmp[2] = str(donecare_list[0][1])\n",
    "                    b_tmp[3] = str(donecare_list[0][2])\n",
    "                    b_tmp[4] = str(new_list[0][0])\n",
    "                    b_tmp[5] = str(new_list[0][1])\n",
    "                    b_tmp[6] = str(new_list[0][2])\n",
    "                    b_tmp[7] = str(new_list[0][3])\n",
    "                    b_tmp[8] = str(donecare_list[2][0])\n",
    "                    b_tmp[9] = str(donecare_list[2][1])\n",
    "                    b_tmp[10] = str(donecare_list[2][2])\n",
    "                    b_tmp[11] = str(donecare_list[3][0])\n",
    "                    b_tmp[12] = str(donecare_list[3][1])\n",
    "                    b_tmp[13] = str(donecare_list[3][2])\n",
    "                    b_tmp[14] = str(donecare_list[3][3])\n",
    "                    break\n",
    "            elif j == 3:\n",
    "                b_tmp[4] = str(new_list[0][0])\n",
    "                b_tmp[5] = str(new_list[0][1])\n",
    "                b_tmp[6] = str(new_list[0][2])\n",
    "                b_tmp[7] = str(new_list[0][3])\n",
    "                b_tmp[8] = str(new_list[1][0])\n",
    "                b_tmp[9] = str(new_list[1][1])\n",
    "                b_tmp[10] = str(new_list[1][2])\n",
    "                b_tmp[11] = str(new_list[2][0])\n",
    "                b_tmp[12] = str(new_list[2][1])\n",
    "                b_tmp[13] = str(new_list[2][2])\n",
    "            else:\n",
    "                print(\"error\")\n",
    "        #print(b_tmp)\n",
    "        b_tmp = ' '.join(b_tmp)\n",
    "        b[i] = b_tmp \n",
    "        a[i] = b[i] \n",
    "        \n",
    "    a = '\\n'.join(a)\n",
    "    \n",
    "    new_f = open(dataset_label_name,'w')\n",
    "    new_f.write(str(a)+'\\n')\n",
    "\n",
    "    new_f.close()\n",
    "    f.close()\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9ab6cb",
   "metadata": {},
   "source": [
    "# Json Parsing ( AI Hub )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb658f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data_str = ''\n",
    "\n",
    "def json_parsing_old_bbox(json_path):\n",
    "  \n",
    "\n",
    "    old_bbox = []\n",
    "\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "        old_bbox=json_data[\"annotations\"][0]['bbox']\n",
    "        json_data[\"annotations\"][0]['bbox'] = new_bbox\n",
    "        json_data_str = str(json_data)\n",
    "    \n",
    "    return old_bbox\n",
    "\n",
    "\n",
    "\n",
    "def json_parsing_data_write(json_path, new_bbox):\n",
    "    state = 0\n",
    "    \n",
    "    with open(json_path, 'r') as f:\n",
    "        json_data[\"annotations\"][0]['bbox'] = new_bbox\n",
    "        json_data_str = str(json_data)\n",
    "        f.close()\n",
    "\n",
    "        \n",
    "    with open(json_path, 'w') as prj_f:\n",
    "        json_data_str = json_data_str.replace(\"\\'\", \"\\\"\")\n",
    "        json_dict =  json.loads(json_data_str)\n",
    "        json.dump(json_dict, prj_f ,indent = 4, sort_keys=False)\n",
    "        state = 1\n",
    "\n",
    "        \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2825935",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = SourceModule(\"\"\"\n",
    "    __global__ void calculate(float *a){\n",
    "        int idx = threadIdx.x + threadIdx\n",
    "        \n",
    "    }                     \n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f792cb8f",
   "metadata": {},
   "source": [
    "# Json Parsing ( COCO )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e469d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Json Parsing ( AI Hub )\n",
    "\n",
    "json_path = '/home/shkim/Workspace/data/COCO_2017/annotations/'\n",
    "\n",
    "json_data_str = ''\n",
    "\n",
    "json_name = 'person_keypoints_train2017.json'\n",
    "\n",
    "json_id_name = 'instances_val2017.json'\n",
    "\n",
    "\n",
    "new_list = [0.0,0.0,0.0,0.0]\n",
    "\n",
    "image_id_shape_list = []\n",
    "\n",
    "annotation_bbox_list = []\n",
    "\n",
    "tmp_id_image_name = ''\n",
    "\n",
    "json_id_path = json_path + json_id_name\n",
    "\n",
    "json_move_coco_name = ''\n",
    "\n",
    "move_coco_name = ''\n",
    "\n",
    "origin_coco_train_name = '' \n",
    "cnt = 0\n",
    "#coco_origin_path_prefix + coco_train_image_prefix\n",
    "origin_coco_val_name = '' \n",
    "\n",
    "with open(json_id_path , 'r') as f:\n",
    "    #with open(json_path + json_name, 'r') as f2:\n",
    "    json_id_data = json.load(f)\n",
    "    #json_data = json.load(f2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(len(json_id_data[\"images\"])):\n",
    "        image_id_shape_list.append([json_id_data[\"images\"][i][\"id\"],json_id_data[\"images\"][i][\"height\"], json_id_data[\"images\"][i][\"width\"]])\n",
    "    \n",
    "    print(\"make id_shape_list\")\n",
    "    #print(image_id_shape_list)\n",
    "    \n",
    "    for j in range(len(json_id_data[\"annotations\"])):\n",
    "        for i in range(len(image_id_shape_list)):\n",
    "            if(image_id_shape_list[i][0] == json_id_data[\"annotations\"][j][\"image_id\"]):\n",
    "                annotation_bbox_list.append([json_id_data[\"annotations\"][j][\"id\"],image_id_shape_list[i][1],image_id_shape_list[i][2],json_id_data[\"annotations\"][j][\"bbox\"]])\n",
    "                break\n",
    "        \n",
    "    print(\"make annotation_bbox_list\")\n",
    "    #print(annotation_bbox_list)\n",
    "    \n",
    "    \n",
    "    for i in range(len(annotation_bbox_list)):\n",
    "        annotation_bbox_list[i][3] = Equirectangular_Projection(annotation_bbox_list[i][1], annotation_bbox_list[i][2], annotation_bbox_list[i][3] )\n",
    "        cnt +=1\n",
    "    print(\"make annotation_bbox_new_list\")\n",
    "    #print(annotation_bbox_list)\n",
    "        \n",
    "    for i in range(len(annotation_bbox_list)): \n",
    "        for j in range(len(json_id_data[\"annotations\"])):\n",
    "            if(annotation_bbox_list[i][0]==json_id_data[\"annotations\"][j][\"id\"]):\n",
    "                json_id_data[\"annotations\"][j][\"bbox\"] = annotation_bbox_list[i][3]\n",
    "                cnt += 1\n",
    "                break\n",
    "            \n",
    "    print(\"make annotation_bbox_new_json\")\n",
    "\n",
    "    \n",
    "    tmp_path = '/home/shkim/Workspace/data/coco_dataset/annotations/test_json.json'\n",
    "    \n",
    "    with open(tmp_path, 'w') as prj_f:\n",
    "        json.dump(json_id_data, prj_f)\n",
    "        \n",
    "#with open(move_coco_prefix + json_name, 'w') as prj_f:\n",
    "\n",
    "#    state = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb748fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Json Parsing ( AI Hub )\n",
    "\n",
    "json_path = '/home/shkim/Workspace/data/COCO_2017/annotations/'\n",
    "\n",
    "json_data_str = ''\n",
    "\n",
    "json_name = 'person_keypoints_train2017.json'\n",
    "\n",
    "json_id_name = 'instances_train2017.json'\n",
    "\n",
    "\n",
    "new_list = [0.0,0.0,0.0,0.0]\n",
    "\n",
    "points_list = []\n",
    "\n",
    "body_jpg_list = []\n",
    "\n",
    "tmp_id_image_name = ''\n",
    "\n",
    "json_id_path = json_path + json_id_name\n",
    "\n",
    "json_move_coco_name = ''\n",
    "\n",
    "move_coco_name = ''\n",
    "\n",
    "origin_coco_train_name = '' \n",
    "\n",
    "#coco_origin_path_prefix + coco_train_image_prefix\n",
    "origin_coco_val_name = '' \n",
    "\n",
    "with open(json_id_path , 'r') as f:\n",
    "    #with open(json_path + json_name, 'r') as f2:\n",
    "    json_id_data = json.load(f)\n",
    "    #json_data = json.load(f2)\n",
    "    for j in range(len(json_id_data[\"annotations\"])):\n",
    "        if(json_id_data[\"annotations\"][j]['category_id'] == 1):\n",
    "            body_jpg_list.append(json_id_data[\"annotations\"][j][\"image_id\"])\n",
    "        \n",
    "\n",
    "                    #json_id_data[\"annotations\"][j][\"bbox\"] = new_list\n",
    "            #json_data[\"annotations\"][0]['bbox'] = new_bbox\n",
    "            #json_data_str = str(json_data)\n",
    "        \n",
    "        #json_move_coco_name = move_coco_prefix + coco_annotation_prefix + json_id_name\n",
    "        #json.dump(json_id_data, json_move_coco_name ,indent = 4, sort_keys=False)\n",
    "    print(\"category_id list using json parsing complete\")\n",
    "    \n",
    "    \n",
    "    for z in range(len(body_jpg_list)):\n",
    "        for i in range(len(json_id_data[\"images\"])): \n",
    "        #for j in range(len(json_id_data[\"annotations\"])):\n",
    "            if (json_id_data[\"images\"][i][\"id\"] == body_jpg_list[z]):\n",
    "                tmp_id_image_name = json_id_data[\"images\"][i][\"file_name\"]\n",
    "                \n",
    "                #print(tmp_id_image_name)\n",
    "                move_coco_name = move_coco_prefix + coco_val_image_prefix + tmp_id_image_name\n",
    "                origin_coco_val_name = coco_origin_path_prefix + coco_val_image_prefix + tmp_id_image_name\n",
    "                if os.path.isfile(move_coco_name):\n",
    "                    #print('{} image file already exist ... so skeep once'.format(tmp_id_image_name))\n",
    "                    pass\n",
    "                else :\n",
    "\n",
    "                    #image, new_list = Equirectangular_Projection(origin_coco_val_name, new_list)\n",
    "                    image = image_to_equirectangular_projection(origin_coco_val_name, )\n",
    "                    final_image = Image.fromarray(image)\n",
    "                    final_image.save(move_coco_name)\n",
    "                    print('{} image file generate...'.format(tmp_id_image_name))\n",
    "                    \n",
    "            else:\n",
    "                continue\n",
    "        #points_list.append(json_data[\"annotations\"][i][\"bbox\"])\n",
    "        #print(json_data[\"annotations\"][i][\"id\"])\n",
    "        \n",
    "#with open(move_coco_prefix + json_name, 'w') as prj_f:\n",
    "\n",
    "#    state = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afbced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Json Parsing ( AI Hub )\n",
    "\n",
    "json_path = '/home/shkim/Workspace/data/COCO_2017/annotations/'\n",
    "\n",
    "json_data_str = ''\n",
    "\n",
    "json_name = 'person_keypoints_train2017.json'\n",
    "\n",
    "json_id_name = 'instances_val2017.json'\n",
    "\n",
    "points_list = []\n",
    "\n",
    "tmp_id_image_name = ''\n",
    "\n",
    "json_id_path = json_path + json_id_name\n",
    "\n",
    "\n",
    "json_move_coco_name = ''\n",
    "\n",
    "move_coco_name = ''\n",
    "\n",
    "origin_coco_train_name = '' \n",
    "\n",
    "#coco_origin_path_prefix + coco_train_image_prefix\n",
    "origin_coco_val_name = '' \n",
    "\n",
    "with open(json_id_path , 'r') as f:\n",
    "    #with open(json_path + json_name, 'r') as f2:\n",
    "        json_id_data = json.load(f)\n",
    "        #json_data = json.load(f2)\n",
    "        for i in range(len(json_id_data[\"images\"])):\n",
    "            for j in range(len(json_id_data[\"annotations\"])):\n",
    "                if (json_id_data[\"images\"][i][\"id\"] == json_id_data[\"annotations\"][j]['image_id']):\n",
    "                    tmp_id_image_name = json_id_data[\"images\"][i][\"file_name\"]\n",
    "                    \n",
    "                    #print(tmp_id_image_name)\n",
    "                    move_coco_name = move_coco_prefix + coco_val_image_prefix + tmp_id_image_name\n",
    "                    origin_coco_val_name = coco_origin_path_prefix + coco_val_image_prefix + tmp_id_image_name\n",
    "                    \n",
    "                   \n",
    "                    if os.path.isfile(move_coco_name):\n",
    "                        #print('{} image file already exist ... so skeep once'.format(move_coco_name))\n",
    "                        pass\n",
    "                    else :\n",
    "                        image, new_list = Equirectangular_Projection(origin_coco_val_name, json_id_data[\"annotations\"][j][\"bbox\"])\n",
    "                        final_image = Image.fromarray(image)\n",
    "                        final_image.save(move_coco_name)\n",
    "                    #json_id_data[\"annotations\"][j][\"bbox\"] = new_list\n",
    "            #json_data[\"annotations\"][0]['bbox'] = new_bbox\n",
    "            #json_data_str = str(json_data)\n",
    "        \n",
    "        #json_move_coco_name = move_coco_prefix + coco_annotation_prefix + json_id_name\n",
    "        #json.dump(json_id_data, json_move_coco_name ,indent = 4, sort_keys=False)\n",
    "        print(\"json file dump complete\")\n",
    "            #points_list.append(json_data[\"annotations\"][i][\"bbox\"])\n",
    "            #print(json_data[\"annotations\"][i][\"id\"])\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "#with open(move_coco_prefix + json_name, 'w') as prj_f:\n",
    "\n",
    "#    state = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c7e12a",
   "metadata": {},
   "source": [
    "# Draw bbox ( Lisence MIT )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d2a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bboxes(img, bbox, identities=None, offset=(0,0)):\n",
    "    for i,box in enumerate(bbox):\n",
    "        x1,y1,x2,y2 = [int(i) for i in box[1:]]\n",
    "        x1 += offset[0]\n",
    "        x2 += offset[0]\n",
    "        y1 += offset[1]\n",
    "        y2 += offset[1]\n",
    "        # box text and bar\n",
    "        id = int(i)\n",
    "        color = (255,0,0)\n",
    "        label = '{} {}'.format(box[0], id)\n",
    "        t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 2 , 2)[0]\n",
    "        cv2.rectangle(img,(x1, y1),(x2,y2),color,3)\n",
    "        #cv2.rectangle(img,(x1, y1),(x1+t_size[0]-12,y1+t_size[1]-6), color,-1)\n",
    "        cv2.putText(img,label,(x1,y1+t_size[1]), cv2.FONT_HERSHEY_PLAIN, 2, [0,0,0], 4)\n",
    "    return img "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ef89f6",
   "metadata": {},
   "source": [
    "# Searching file & Dataset Making ( coco )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f536006",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(coco_origin_path_prefix + coco_val_image_prefix)\n",
    "for file in file_list:\n",
    "    filename, fileExtension = os.path.splitext(file)\n",
    "    if fileExtension == '.jpg' :\n",
    "        print('find jpg image file......', end=' ')\n",
    "        #print(filename)\n",
    "        #print(fileExtension)\n",
    "        tmp_image_name = filename + pngExtension\n",
    "        tmp_label_name = filename + fileExtension\n",
    "        origin_dataset_image_name = origin_val_path_prefix + tmp_image_name\n",
    "        origin_dataset_label_name = origin_val_path_prefix + tmp_label_name\n",
    "        dataset_image_name = move_coco_prefix + coco_val_image_prefix + tmp_image_name\n",
    "        dataset_label_name = move_coco_prefix + coco_val_image_prefix + tmp_label_name\n",
    "        if os.path.isfile(dataset_image_name):\n",
    "            print('{} image file already exist ... so skeep once'.format(dataset_image_name))\n",
    "        else :\n",
    "            image = image_to_(origin_dataset_image_name ,  )\n",
    "            #image = img_label_(origin_dataset_image_name, origin_dataset_label_name, dataset_label_name, origin_list)\n",
    "            final_image = Image.fromarray(image)\n",
    "            final_image.save(dataset_image_name)\n",
    "            print(\" done\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62226053",
   "metadata": {},
   "source": [
    "# Searching file & Dataset Making ( kitti )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aae0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(origin_path_prefix + label_prefix)\n",
    "for file in file_list:\n",
    "    filename, fileExtension = os.path.splitext(file)\n",
    "    if fileExtension == '.txt' :\n",
    "        print('find label txt file......', end=' ')\n",
    "        #print(filename)\n",
    "        #print(fileExtension)\n",
    "        tmp_image_name = filename + pngExtension\n",
    "        tmp_label_name = filename + fileExtension\n",
    "        origin_dataset_image_name = origin_path_prefix + image_prefix + tmp_image_name\n",
    "        origin_dataset_label_name = origin_path_prefix + label_prefix + tmp_label_name\n",
    "        dataset_image_name = move_path_prefix + image_prefix + tmp_image_name\n",
    "        dataset_label_name = move_path_prefix + label_prefix + tmp_label_name\n",
    "        if os.path.isfile(dataset_image_name):\n",
    "            print('{} image file already exist ... so skeep once'.format(ataset_image_name))\n",
    "        else :\n",
    "            image = image_to_equirectangular_projection(origin_dataset_image_name )\n",
    "            #image = img_label_projection(origin_dataset_image_name, origin_dataset_label_name, dataset_label_name, origin_list)\n",
    "            final_image = Image.fromarray(image)\n",
    "            final_image.save(dataset_image_name)\n",
    "            print(\" done\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd96979",
   "metadata": {},
   "source": [
    "# Annotating Image ( From Image )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42cd334",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(move_path_prefix + image_prefix)\n",
    "for file in file_list:\n",
    "    filename, fileExtension = os.path.splitext(file)\n",
    "    if fileExtension == '.png' :\n",
    "        print('find equirectangular png file' )\n",
    "        \n",
    "        #print(filename)\n",
    "        #print(fileExtension)\n",
    "        bbox =[]\n",
    "        tmp_image_name = filename + pngExtension\n",
    "        tmp_label_name = filename + txtExtension\n",
    "        image = cv2.imread(move_path_prefix + image_prefix + tmp_image_name,cv2.IMREAD_COLOR)\n",
    "        label_f = open(move_path_prefix + label_prefix + tmp_label_name, 'r')\n",
    "        a = label_f .read().splitlines()\n",
    "        b = deepcopy(a)\n",
    "\n",
    "        for i in range(len(b)):\n",
    "            b_tmp = b[i].split(' ')\n",
    "            bbox.append([str(b_tmp[0]),float(b_tmp[4]),float(b_tmp[5]),float(b_tmp[6]),float(b_tmp[7])])\n",
    "        \n",
    "        img = draw_bboxes(image,bbox)\n",
    "        img = Image.fromarray(img)\n",
    "        img.save(move_path_prefix + annotation_prefix + tmp_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb32d432",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c975e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from math import ceil\n",
    "valid_image_ext = ['.jpg', '.png', '.jpeg', '.ppm']\n",
    "\n",
    "def visualize_images(image_dir, num_cols=4, num_images=10):\n",
    "    output_path = image_dir\n",
    "    num_rows = int(ceil(float(num_images) / float(num_cols)))\n",
    "    f, axarr = plt.subplots(num_rows, num_cols, figsize=[80,30])\n",
    "    f.tight_layout()\n",
    "    a = [os.path.join(output_path, image) for image in os.listdir(output_path) \n",
    "         if os.path.splitext(image)[1].lower() in valid_image_ext]\n",
    "    for idx, img_path in enumerate(a[:num_images]):\n",
    "        col_id = idx % num_cols\n",
    "        row_id = idx // num_cols\n",
    "        img = plt.imread(img_path)\n",
    "        axarr[row_id, col_id].imshow(img) \n",
    "        \n",
    "        \n",
    "# Visualizing the first 12 images.\n",
    "OUTPUT_PATH = visual_path # relative path from $USER_EXPERIMENT_DIR.\n",
    "COLS = 4 # number of columns in the visualizer grid.\n",
    "IMAGES = 12 # number of images to visualize.\n",
    "\n",
    "visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e145fa6",
   "metadata": {},
   "source": [
    "# TODO Test Origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645bf9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_path = '/home/shkim/Workspace/data/training/'\n",
    "\n",
    "\n",
    "file_list = os.listdir(tmp_path + image_prefix)\n",
    "for file in file_list:\n",
    "    filename, fileExtension = os.path.splitext(file)\n",
    "    if fileExtension == '.png' :\n",
    "        print('find png file' )\n",
    "        \n",
    "        #print(filename)\n",
    "        #print(fileExtension)\n",
    "        bbox =[]\n",
    "        tmp_image_name = filename + pngExtension\n",
    "        tmp_label_name = filename + txtExtension\n",
    "        image = cv2.imread(tmp_path + image_prefix + tmp_image_name,cv2.IMREAD_COLOR)\n",
    "        label_f = open(tmp_path  + label_prefix + tmp_label_name, 'r')\n",
    "        a = label_f .read().splitlines()\n",
    "        b = deepcopy(a)\n",
    "\n",
    "        for i in range(len(b)):\n",
    "            b_tmp = b[i].split(' ')\n",
    "            bbox.append([str(b_tmp[0]),float(b_tmp[4]),float(b_tmp[5]),float(b_tmp[6]),float(b_tmp[7])])\n",
    "        \n",
    "        img = draw_bboxes(image,bbox)\n",
    "        img = Image.fromarray(img)\n",
    "        img.save(tmp_path + annotation_prefix + tmp_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d17525",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = '/home/shkim/Workspace/data/test/000000000077.jpg'\n",
    "test_dest1 = '/home/shkim/Workspace/data/test/77equ.jpg'\n",
    "test_dest2 = '/home/shkim/Workspace/data/test/77label.jpg'\n",
    "\n",
    "image = image_to_equirectangular_projection(test_image , )\n",
    "image2, new_list = Equirectangular_Projection(test_image, origin_list)\n",
    "final_image = Image.fromarray(image)\n",
    "final_image.save(test_dest1)\n",
    "final_image2 = Image.fromarray(image2)\n",
    "final_image2.save(test_dest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb03b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_tmp_path = '/home/shkim/Workspace/data/coco_dataset/annotations/person_keypoints_val2017.json'\n",
    "\n",
    "\n",
    "file_val_data = OrderedDict()\n",
    "\n",
    "file_val_data[\"info\"] = {\"description\": \"COCO 2017 Dataset\",\"url\": \"http://cocodataset.org\",\"version\": \"1.0\",\"year\": 2017,\"contributor\": \"COCO Consortium\",\"date_created\": \"2017/09/01\"}\n",
    "file_val_data[\"licenses\"] = []\n",
    "file_val_data[\"images\"] = []\n",
    "file_val_data[\"annotations\"] = []\n",
    "file_val_data[\"categories\"] = [{\"supercategory\": \"person\",\"id\": 1,\"name\": \"person\",\"keypoints\": [\"nose\",\"left_eye\",\"right_eye\",\"left_ear\",\"right_ear\",\"left_shoulder\",\"right_shoulder\",\"left_elbow\",\"right_elbow\",\"left_wrist\",\"right_wrist\",\"left_hip\",\"right_hip\",\"left_knee\",\"right_knee\",\"left_ankle\",\"right_ankle\"],\"skeleton\": [[16,14],[14,12],[17,15],[15,13],[12,13],[6,12],[7,13],[6,7],[6,8],[7,9],[8,10],[9,11],[2,3],[1,2],[1,3],[2,4],[3,5],[4,6],[5,7]]}]\n",
    "\n",
    "state = 0\n",
    "\n",
    "tmp_id_list = []\n",
    "\n",
    "tmp_cnt = 0\n",
    "\n",
    "with open(json_tmp_path , 'r') as f:\n",
    "    json_id_data = json.load(f) \n",
    "    tmp_file_path = '/home/shkim/Workspace/data/coco_dataset/val2017'\n",
    "    tmp_deep_list = list(copy.deepcopy(json_id_data[\"images\"]))\n",
    "    print(len(json_id_data[\"images\"]))\n",
    "    for i in range(len(json_id_data[\"images\"])):\n",
    "        file_list = os.listdir(tmp_file_path)\n",
    "        #print(len(file_list))\n",
    "        tmp_image_dict = json_id_data[\"images\"][i]\n",
    "        tmp_image_list = list(tmp_image_dict.values())\n",
    "        #print(tmp_image_list)\n",
    "        for file in file_list:\n",
    "            if (file == tmp_image_list[1] ) :\n",
    "                state = 1\n",
    "                break\n",
    "            else :\n",
    "                state = 0\n",
    "        if state == 0 :\n",
    "            tmp_id_list.append(tmp_image_list[7])\n",
    "    \n",
    "    \n",
    "    #print(tmp_id_list)\n",
    "    for id in tmp_id_list:\n",
    "        for i in range(len(json_id_data[\"images\"])):\n",
    "            tmp_image_dict = json_id_data[\"images\"][i]\n",
    "            tmp_image_list = list(tmp_image_dict.values())\n",
    "            #print(tmp_image_list)\n",
    "            if(id == tmp_image_list[7]):\n",
    "                tmp_deep_list.remove(json_id_data[\"images\"][i])\n",
    "                #tmp_cnt+=1\n",
    "\n",
    "    file_val_data[\"images\"] = tmp_deep_list\n",
    "    print(len(file_data[\"images\"]))\n",
    "    file_val_data[\"annotations\"] = json_id_data[\"annotations\"]\n",
    "        \n",
    "    \n",
    "tmp_path = '/home/shkim/Workspace/data/coco_dataset/annotations/test_val_json.json'\n",
    "\n",
    "with open(tmp_path, 'w') as prj_f:\n",
    "    json.dump(file_val_data, prj_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c92a864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total image len :  118287\n",
      "generate tmp_bbox_list\n",
      "equ image generate using tmp_bbox_list\n",
      "json_data change using tmp_bbox_list \n",
      "json_file generate \n"
     ]
    }
   ],
   "source": [
    "json_tmp_path = '/home/shkim/Workspace/data/COCO_2017/annotations/person_keypoints_train2017.json'\n",
    "\n",
    "\n",
    "file_data = OrderedDict()\n",
    "\n",
    "file_data[\"info\"] = {\"description\": \"COCO 2017 Dataset\",\"url\": \"http://cocodataset.org\",\"version\": \"1.0\",\"year\": 2017,\"contributor\": \"COCO Consortium\",\"date_created\": \"2017/09/01\"}\n",
    "file_data[\"licenses\"] = [{\"url\": \"\",\"id\": 1,\"name\": \"\"},{\"url\": \"\",\"id\": 2,\"name\": \"\"},{\"url\": \"\"}]\n",
    "file_data[\"images\"] = []\n",
    "file_data[\"annotations\"] = []\n",
    "file_data[\"categories\"] = [{\"supercategory\": \"person\",\"id\": 1,\"name\": \"person\",\"keypoints\": [\"nose\",\"left_eye\",\"right_eye\",\"left_ear\",\"right_ear\",\"left_shoulder\",\"right_shoulder\",\"left_elbow\",\"right_elbow\",\"left_wrist\",\"right_wrist\",\"left_hip\",\"right_hip\",\"left_knee\",\"right_knee\",\"left_ankle\",\"right_ankle\"],\"skeleton\": [[16,14],[14,12],[17,15],[15,13],[12,13],[6,12],[7,13],[6,7],[6,8],[7,9],[8,10],[9,11],[2,3],[1,2],[1,3],[2,4],[3,5],[4,6],[5,7]]}]\n",
    "\n",
    "state = 0\n",
    "\n",
    "tmp_id_list = []\n",
    "\n",
    "tmp_bbox_list = []\n",
    "\n",
    "tmp_image_list = []\n",
    "\n",
    "tmp_cnt = 0\n",
    "\n",
    "with open(json_tmp_path , 'r') as f:\n",
    "    json_id_data = json.load(f) \n",
    "    tmp_file_path = '/home/shkim/Workspace/data/COCO_2017/train2017/'\n",
    "    print(\"total image len : \",len(json_id_data[\"images\"]))\n",
    "    for i in range(len(json_id_data[\"images\"])):\n",
    "        tmp_image_dict = json_id_data[\"images\"][i]\n",
    "        tmp_image_list = list(tmp_image_dict.values())\n",
    "\n",
    "        tmp_image_path = tmp_file_path + tmp_image_list[1]\n",
    "        move_path = move_coco_prefix + coco_train_image_prefix + tmp_image_list[1]\n",
    "        \n",
    "        for j in range(len(json_id_data[\"annotations\"])):\n",
    "            tmp_anno_dict = json_id_data[\"annotations\"][j]\n",
    "            tmp_anno_list = list(tmp_anno_dict.values())\n",
    "            if(tmp_anno_list[5] == tmp_image_list[7]):\n",
    "                tmp_bbox_list.append([tmp_image_path,move_path,tmp_image_list[7],tmp_anno_list[8],tmp_anno_list[6],tmp_anno_list[7]])\n",
    "                tmp_cnt+=1\n",
    "    print(\"generate tmp_bbox_list\")            \n",
    "    for i in range(len(tmp_bbox_list)):\n",
    "        \n",
    "        if os.path.isfile(tmp_bbox_list[i][1]):\n",
    "            continue\n",
    "        else:\n",
    "            if tmp_bbox_list[i][5] == 1 :\n",
    "                #print(\"image name\",tmp_bbox_list[i][1])\n",
    "                #print(\"before bbox\",tmp_bbox_list[i][4])\n",
    "                image, tmp_bbox_list[i][4] = Equirectangular_Projection(tmp_bbox_list[i][0], tmp_bbox_list[i][4])\n",
    "                #print(\"after bbox\",tmp_bbox_list[i][4])\n",
    "                final_image = Image.fromarray(image)\n",
    "                final_image.save(tmp_bbox_list[i][1])\n",
    "                #print(\"equ image generate\")\n",
    "            else:\n",
    "                #print(\"equ image generate skip\")\n",
    "                continue\n",
    "\n",
    "\n",
    "    print(\"equ image generate using tmp_bbox_list\")\n",
    "    for i in range(len(tmp_bbox_list)):\n",
    "        for j in range(len(json_id_data[\"annotations\"])):\n",
    "            tmp_anno_list = list(json_id_data[\"annotations\"][j].values())\n",
    "            #print(tmp_anno_list)\n",
    "            if(tmp_bbox_list[i][3] == tmp_anno_list[8]):\n",
    "                json_id_data[\"annotations\"][j][\"bbox\"] = tmp_bbox_list[i][4]\n",
    "                #print(\"change\")\n",
    "                break\n",
    "    print(\"json_data change using tmp_bbox_list \")\n",
    "    file_data[\"images\"] = json_id_data[\"images\"]\n",
    "    file_data[\"annotations\"] = json_id_data[\"annotations\"]\n",
    "        \n",
    "    \n",
    "tmp_path = '/home/shkim/Workspace/data/coco_dataset/annotations/test_json.json'\n",
    "\n",
    "with open(tmp_path, 'w') as prj_f:\n",
    "    json.dump(file_data, prj_f)\n",
    "    \n",
    "\n",
    "print(\"json_file generate \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086e6cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_id_path , 'r') as f:\n",
    "    #with open(json_path + json_name, 'r') as f2:\n",
    "    json_id_data = json.load(f)\n",
    "    #json_data = json.load(f2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(len(json_id_data[\"images\"])):\n",
    "        image_id_shape_list.append([json_id_data[\"images\"][i][\"id\"],json_id_data[\"images\"][i][\"height\"], json_id_data[\"images\"][i][\"width\"]])\n",
    "    \n",
    "    print(\"make id_shape_list\")\n",
    "    #print(image_id_shape_list)\n",
    "    \n",
    "    for j in range(len(json_id_data[\"annotations\"])):\n",
    "        for i in range(len(image_id_shape_list)):\n",
    "            if(image_id_shape_list[i][0] == json_id_data[\"annotations\"][j][\"image_id\"]):\n",
    "                annotation_bbox_list.appendexit([json_id_data[\"annotations\"][j][\"id\"],image_id_shape_list[i][1],image_id_shape_list[i][2],json_id_data[\"annotations\"][j][\"bbox\"]])\n",
    "                break\n",
    "        \n",
    "    print(\"make annotation_bbox_list\")\n",
    "    #print(annotation_bbox_list)\n",
    "    \n",
    "    \n",
    "    for i in range(len(annotation_bbox_list)):\n",
    "        annotation_bbox_list[i][3] = Equirectangular_Projection(annotation_bbox_list[i][1], annotation_bbox_list[i][2], annotation_bbox_list[i][3] )\n",
    "        cnt +=1\n",
    "    print(\"make annotation_bbox_new_list\")\n",
    "    #print(annotation_bbox_list)\n",
    "        \n",
    "    for i in range(len(annotation_bbox_list)): \n",
    "        for j in range(len(json_id_data[\"annotations\"])):\n",
    "            if(annotation_bbox_list[i][0]==json_id_data[\"annotations\"][j][\"id\"]):\n",
    "                json_id_data[\"annotations\"][j][\"bbox\"] = annotation_bbox_list[i][3]\n",
    "                cnt += 1\n",
    "                break\n",
    "            \n",
    "    print(\"make annotation_bbox_new_json\")\n",
    "\n",
    "    \n",
    "    tmp_path = '/home/shkim/Workspace/data/coco_dataset/annotations/test_json.json'\n",
    "    \n",
    "    with open(tmp_path, 'w') as prj_f:\n",
    "        json.dump(json_id_data, prj_f)\n",
    "        \n",
    "#with open(move_coco_prefix + json_name, 'w') as prj_f:\n",
    "\n",
    "#    state = 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "641a55d8939525ed3a758c40e0b2cd8a45f46ed25f79ebaec06653f3236ef84e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
